{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b4fcbbf9",
      "metadata": {
        "id": "b4fcbbf9"
      },
      "source": [
        "# Phase 3 - Vehicle Classification\n",
        "\n",
        "This is an open ended phase. You must build a classifier for the Stanford Cars Dataset. You can use any techniques and knowledge from Phase 1 & 2 to aid you. The ultimate goal is to get as good performance as you can on the test set.\n",
        "\n",
        "Please follow TA instructions in lab to learn how to access the data.\n",
        "\n",
        "**Note**: You will need to achieve more than 80% accuracy on the test set to receive credit for Phase 3!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1db58858",
      "metadata": {
        "id": "1db58858"
      },
      "source": [
        "# Imports\n",
        "\n",
        "Import all the libraries you need for your project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3_HZ_0UQBX6",
        "outputId": "120444aa-aa72-45c1-8804-242c29bd4ac0"
      },
      "id": "T3_HZ_0UQBX6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "973648bc",
      "metadata": {
        "id": "973648bc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import utils\n",
        "import torchvision.models as models\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXnghzpD1luc",
        "outputId": "4dc501f5-f8a5-4718-971d-2793ab61887e"
      },
      "id": "AXnghzpD1luc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60b0e403",
      "metadata": {
        "id": "60b0e403"
      },
      "source": [
        "## 1) Load Dataset\n",
        "The Stanford Dataset is not provided in ```torchvision.datasets```. You will need to create your inherit from ```Dataset``` class to load the dataset and overload the ```___init__()```, ```__len__()```, and ```__getitem__()``` functions.\n",
        "\n",
        "You will find the following link useful to help create the dataset class: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "If you wish, you can create another method in the class: ```visualize()``` to help visualize the data. This is optional and will not be graded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3d9953",
      "metadata": {
        "id": "9f3d9953"
      },
      "outputs": [],
      "source": [
        "class CarDataSet(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.car_data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.car_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # if torch.is_tensor(idx):\n",
        "        #     idx = idx.tolist()\n",
        "        #     img_name = os.path.join(self.root_dir,\n",
        "        #                         self.car_data.iloc[idx, 0])\n",
        "        #     image = io.imread(img_name)\n",
        "        #     labels = self.car_data.iloc[idx, 1:]\n",
        "        #     labels = np.array([labels], dtype=float).reshape(-1, 2)\n",
        "        #     sample = {'image': image, 'labels': labels}\n",
        "\n",
        "        #     if self.transform:\n",
        "        #         sample = self.transform(sample)\n",
        "\n",
        "        #     return sample\n",
        "        img_path = os.path.join(self.root_dir, self.car_data.iloc[idx, 0])\n",
        "        image = Image.open(img_path)\n",
        "        image = image.convert(\"RGB\")\n",
        "        label = self.car_data.iloc[idx, -1] -1\n",
        "\n",
        "        # print(type(image))\n",
        "        # print(image.size)\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "\n",
        "        # print(type(image))\n",
        "        # print(image.shape)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a029cc2d",
      "metadata": {
        "id": "a029cc2d"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    # transforms.RandomResizedCrop(224),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x),\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "train_data = CarDataSet(csv_file='/content/drive/MyDrive/Colab Notebooks/stanford_cars_eec174/train_make.csv',\n",
        "                                           root_dir='/content/drive/MyDrive/Colab Notebooks/stanford_cars_eec174/images/train',\n",
        "                                           transform=transform)\n",
        "test_data = CarDataSet(csv_file='/content/drive/MyDrive/Colab Notebooks/stanford_cars_eec174/val_make.csv',\n",
        "                                           root_dir='/content/drive/MyDrive/Colab Notebooks/stanford_cars_eec174/images/val',\n",
        "                                           transform=transform)\n",
        "\n",
        "# Batch Size\n",
        "batch_size = 64\n",
        "\n",
        "# # Import to Dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad2acc24",
      "metadata": {
        "id": "ad2acc24"
      },
      "source": [
        "## 2) Define your Model Architecture\n",
        "\n",
        "It is up to you to decide which model you use. You can create yor own CNN or use transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0019e8",
      "metadata": {
        "id": "ed0019e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2fdb9b-f896-4a2b-c5de-722e10b49652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=49, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Model definition\n",
        "resnet18 = models.resnet50(pretrained=True)\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, 49)\n",
        "# Load Model onto GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "resnet18.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfa8640d",
      "metadata": {
        "id": "bfa8640d"
      },
      "source": [
        "## 3) Define Loss function and Optimizer\n",
        "\n",
        "You chose the loss function and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9)\n",
        "# scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "NwqrLlxS7twS"
      },
      "id": "NwqrLlxS7twS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "79da9193",
      "metadata": {
        "id": "79da9193"
      },
      "source": [
        "## 4) Train your Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ad54c7",
      "metadata": {
        "id": "69ad54c7"
      },
      "outputs": [],
      "source": [
        "def train(model, loss_fn, optimizer, train_loader, valid_loader, batch_size, num_epochs, device):\n",
        "    if device is not None:\n",
        "        model.to(device)\n",
        "    else:\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    valid_losses = []  # Track validation loss\n",
        "    valid_accuracies = []  # Track validation accuracy\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        start_time = time.time()\n",
        "        # print(\"loader\")\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # print(i)\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            # print('-'*20)\n",
        "            # print(outputs)\n",
        "            # print('='*20)\n",
        "            # print(labels)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            # print(\"Loss: {}\".format(loss.item()))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_accuracy = 100 * correct / total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        valid_running_loss = 0.0\n",
        "        valid_correct = 0\n",
        "        valid_total = 0\n",
        "        for i, data in enumerate(valid_loader, 0):\n",
        "            # print(\"valid\")\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            valid_running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            valid_total += labels.size(0)\n",
        "            valid_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        valid_epoch_loss = valid_running_loss / len(valid_loader)\n",
        "        valid_epoch_accuracy = 100 * valid_correct / valid_total\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        # Print statistics\n",
        "        print('Epoch [%d/%d], Train Loss: %.4f, Train Accuracy: %.4f, Valid Loss: %.4f, Valid Accuracy: %.4f, Time: %.2fs'\n",
        "              % (epoch + 1, num_epochs, epoch_loss, epoch_accuracy, valid_epoch_loss, valid_epoch_accuracy, elapsed_time))\n",
        "\n",
        "        # Append to the lists\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_accuracy)\n",
        "        valid_losses.append(valid_epoch_loss)\n",
        "        valid_accuracies.append(valid_epoch_accuracy)\n",
        "\n",
        "    return train_losses, train_accuracies, valid_losses, valid_accuracies\n",
        "\n",
        "def test_accuracy(model, test_loader, loss_function, device):\n",
        "    model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for test_data in test_loader:\n",
        "            images, labels = test_data[0].cuda(), test_data[1].cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print('Accuracy: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8287fe6d",
      "metadata": {
        "id": "8287fe6d"
      },
      "source": [
        "## 4) Evaluate (on Test Set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6cd42f8",
      "metadata": {
        "id": "c6cd42f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac053929-434a-40ec-9f8d-4fe5eff2d251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 2.2807, Train Accuracy: 39.9116, Valid Loss: 1.8890, Valid Accuracy: 48.9423, Time: 2191.07s\n",
            "Epoch [2/10], Train Loss: 0.8870, Train Accuracy: 74.2601, Valid Loss: 1.3545, Valid Accuracy: 61.9660, Time: 168.40s\n",
            "Epoch [3/10], Train Loss: 0.3709, Train Accuracy: 89.2669, Valid Loss: 1.0691, Valid Accuracy: 70.5516, Time: 167.94s\n",
            "Epoch [4/10], Train Loss: 0.1702, Train Accuracy: 95.3580, Valid Loss: 0.8769, Valid Accuracy: 77.8100, Time: 168.59s\n",
            "Epoch [5/10], Train Loss: 0.0518, Train Accuracy: 98.8825, Valid Loss: 0.7251, Valid Accuracy: 79.8839, Time: 168.18s\n",
            "Epoch [6/10], Train Loss: 0.0476, Train Accuracy: 98.8088, Valid Loss: 0.7847, Valid Accuracy: 79.6765, Time: 168.16s\n",
            "Epoch [7/10], Train Loss: 0.0379, Train Accuracy: 99.1649, Valid Loss: 0.5938, Valid Accuracy: 84.1560, Time: 170.82s\n",
            "Epoch [8/10], Train Loss: 0.0126, Train Accuracy: 99.8158, Valid Loss: 0.5388, Valid Accuracy: 85.6491, Time: 170.22s\n",
            "Epoch [9/10], Train Loss: 0.0050, Train Accuracy: 99.9632, Valid Loss: 0.5043, Valid Accuracy: 86.3957, Time: 171.11s\n",
            "Epoch [10/10], Train Loss: 0.0016, Train Accuracy: 100.0000, Valid Loss: 0.4790, Valid Accuracy: 86.9764, Time: 170.61s\n",
            "Accuracy: 86 %\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "lr = 0.01\n",
        "num_classes = 49\n",
        "\n",
        "# Define Loss func and Optimizer\n",
        "# loss_function = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.7)\n",
        "\n",
        "# Train Model\n",
        "# train_losses, train_accuracies = train(resnet18, loss_function, optimizer, train_loader, test_loader, batch_size, num_epochs, device)\n",
        "train_losses, train_accuracies, valid_losses, valid_accuracies = train(resnet18, loss_function, optimizer, train_loader, test_loader, batch_size, num_epochs, device)\n",
        "\n",
        "# Evaluate on Test Set\n",
        "test_accuracy(resnet18, test_loader, loss_function, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/Colab Notebooks/Copy of Phase_3.ipynb'\n",
        "torch.save(resnet18.state_dict(), PATH)\n",
        "resnet18.load_state_dict(torch.load( PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1cuxc_2nZ2h",
        "outputId": "94e19903-566a-49f5-b472-218f6b668d24"
      },
      "id": "K1cuxc_2nZ2h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Report\n",
        "\n",
        "Please write a report discussing all your choices and procedure to implement your vehicle classifier. In your report, include all your choices (i.e. hyperparameters, lr, models, loss, optimizer) and explain why you made those choices to achieve your performance. Your report must be thorough and comprehensive, please discuss fully how you were able to obtain a high performance."
      ],
      "metadata": {
        "id": "3EB0LqCMieIh"
      },
      "id": "3EB0LqCMieIh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We built a Dataset using the functions given in the starter code, the get item function in the dataset was important as it is the main function which opens the images from the root_dir(the location of the images). Then we transform the image by resizing the image and transforming it into a Tensor so that we can pass it into the model. To cut time on training and improving accuracy we used a resnet50 model. Initially we tried the resnet18 model, however the resnet50 gave us better accuracy so we switched to it. The learning rate is set to 0.01 as when we tried a lower learning rate it was overfitting, and when we switched to a higher one it was converging very fast so we decided to stick to this. The batch size could have been 128 however due to the GPU restrictions and the accuracy being better on 64 for this run we stuck to 64. The optimizer which was better for our model was SGD, which we compared to ADAM."
      ],
      "metadata": {
        "id": "urbQqxtpetvU"
      },
      "id": "urbQqxtpetvU"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}